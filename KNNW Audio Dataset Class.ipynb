{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.6.0\n",
      "  Downloading torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 2.9 kB/s s eta 0:00:01     |████████▋                       | 200.8 MB 133.1 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.6.0) (1.19.5)\n",
      "Requirement already satisfied: future in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.6.0) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed torch-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.5.3\n",
      "  Downloading kaggle-1.5.3.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle==1.5.3) (1.15.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle==1.5.3) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle==1.5.3) (2.8.1)\n",
      "Requirement already satisfied: requests in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle==1.5.3) (2.25.1)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle==1.5.3) (4.57.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle==1.5.3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle==1.5.3) (3.0.4)\n",
      "Building wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.3-py3-none-any.whl size=64984 sha256=4d087dd1eea25396a7f42fb3f85ddd724eb961d51846f990a92fbb6834221bfa\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/74/0f/38/e28f5c722daa06dec06be57c42185be6abd31d8f2ac90d5129\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6769 sha256=81cb0874249267cd222e2cc9c7765cecdf23f5a1c3c7bb40d96fd3e1ee33a858\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/72/e6/db/122611605e60148f54ee2abaca98b2bbeafc6e22486a867bad\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: urllib3, text-unidecode, python-slugify, kaggle\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.4\n",
      "    Uninstalling urllib3-1.26.4:\n",
      "      Successfully uninstalled urllib3-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\n",
      "botocore 1.20.15 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.24.3 which is incompatible.\n",
      "aiobotocore 1.2.1 requires botocore<1.19.53,>=1.19.52, but you have botocore 1.20.15 which is incompatible.\u001b[0m\n",
      "Successfully installed kaggle-1.5.3 python-slugify-4.0.1 text-unidecode-1.3 urllib3-1.24.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/bin/kaggle\", line 5, in <module>\n",
      "    from kaggle.cli import main\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/kaggle/__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/kaggle/api/kaggle_api_extended.py\", line 116, in authenticate\n",
      "    self.config_file, self.config_dir))\n",
      "OSError: Could not find kaggle.json. Make sure it's located in /home/ubuntu/.kaggle. Or use the environment method.\n",
      "mkdir: cannot create directory ‘.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle==1.5.3\n",
    "!kaggle -v\n",
    "!mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 3.8 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=a6622b1948f65b7eaea09bbeb1c6780c2e2d5a395e4e3b42247cdeae4dfcd7d8\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/77/47/e4/44a4ba1b7dfd53faaa35f59f1175e123b213ff401a8a56876b\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.5.3\n",
      "    Uninstalling kaggle-1.5.3:\n",
      "      Successfully uninstalled kaggle-1.5.3\n",
      "Successfully installed kaggle-1.5.12\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "% cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-levenshtein in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.12.2)\r\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-levenshtein) (49.6.0.post20210108)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ctcdecode'...\n",
      "remote: Enumerating objects: 1063, done.\u001b[K\n",
      "remote: Total 1063 (delta 0), reused 0 (delta 0), pack-reused 1063\u001b[K\n",
      "Receiving objects: 100% (1063/1063), 759.71 KiB | 11.51 MiB/s, done.\n",
      "Resolving deltas: 100% (513/513), done.\n",
      "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
      "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
      "Cloning into '/home/ubuntu/ctcdecode/third_party/ThreadPool'...\n",
      "remote: Enumerating objects: 82, done.        \n",
      "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
      "Cloning into '/home/ubuntu/ctcdecode/third_party/kenlm'...\n",
      "remote: Enumerating objects: 13687, done.        \n",
      "remote: Total 13687 (delta 0), reused 0 (delta 0), pack-reused 13687        \n",
      "Receiving objects: 100% (13687/13687), 5.46 MiB | 23.20 MiB/s, done.\n",
      "Resolving deltas: 100% (7880/7880), done.\n",
      "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
      "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=8410523c9f1b2f98298f7258a8092a4de8b93f179967a896ca05f162e6165d9c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "/home/ubuntu/ctcdecode\n",
      "Processing /home/ubuntu/ctcdecode\n",
      "Building wheels for collected packages: ctcdecode\n",
      "  Building wheel for ctcdecode (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp36-cp36m-linux_x86_64.whl size=1338113 sha256=b21f0edc599a042452f19da6c3eab56229f530fc62eda1ba56828e9009909428\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8fjp8iwq/wheels/f7/c1/c2/5b9a3a76509bd10e864cc3d4757eed529617ebf3c17dabeb97\n",
      "Successfully built ctcdecode\n",
      "Installing collected packages: ctcdecode\n",
      "Successfully installed ctcdecode-1.0.2\n",
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget\n",
    "%cd ctcdecode\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torchvision   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "cuda = torch.cuda.is_available()\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitle Lookup Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Start time in milliseconds</th>\n",
       "      <th>End time in milliseconds</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1650</td>\n",
       "      <td>10800</td>\n",
       "      <td>TOHO CORPORATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53940</td>\n",
       "      <td>58090</td>\n",
       "      <td>Some mornings, I wake up crying without knowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>58700</td>\n",
       "      <td>61440</td>\n",
       "      <td>That's when everything happens now and again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>62060</td>\n",
       "      <td>66540</td>\n",
       "      <td>Whatever that dream was I had, I can never rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66540</td>\n",
       "      <td>69550</td>\n",
       "      <td>- But... - But...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  Start time in milliseconds  End time in milliseconds  \\\n",
       "0       1                        1650                     10800   \n",
       "1       2                       53940                     58090   \n",
       "2       3                       58700                     61440   \n",
       "3       4                       62060                     66540   \n",
       "4       5                       66540                     69550   \n",
       "\n",
       "                                                Text  \n",
       "0                                   TOHO CORPORATION  \n",
       "1  Some mornings, I wake up crying without knowin...  \n",
       "2      That's when everything happens now and again.  \n",
       "3  Whatever that dream was I had, I can never rem...  \n",
       "4                                  - But... - But...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Subtitle Lookup Preview:\")\n",
    "pandas.read_table(\"knnw_en_sub.csv\", sep = \";\", header=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 1370582)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Audio Shape:\")\n",
    "numpy.load(\"knnw_en.log_spectrogram.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map_str = \"\"\"\n",
    " <SPACE> 0\n",
    " a 1\n",
    " b 2\n",
    " c 3\n",
    " d 4\n",
    " e 5\n",
    " f 6\n",
    " g 7\n",
    " h 8\n",
    " i 9\n",
    " j 10\n",
    " k 11\n",
    " l 12\n",
    " m 13\n",
    " n 14\n",
    " o 15\n",
    " p 16\n",
    " q 17\n",
    " r 18\n",
    " s 19\n",
    " t 20\n",
    " u 21\n",
    " v 22\n",
    " w 23\n",
    " x 24\n",
    " y 25\n",
    " z 26\n",
    " A 27\n",
    " B 28\n",
    " C 29\n",
    " D 30\n",
    " E 31\n",
    " F 32\n",
    " G 33\n",
    " H 34\n",
    " I 35\n",
    " J 36\n",
    " K 37\n",
    " L 38\n",
    " M 39\n",
    " N 40\n",
    " O 41\n",
    " P 42\n",
    " Q 43\n",
    " R 44\n",
    " S 45\n",
    " T 46\n",
    " U 47\n",
    " V 48\n",
    " W 49\n",
    " X 50\n",
    " Y 51\n",
    " X 52\n",
    " - 53\n",
    " . 54\n",
    " , 55\n",
    " ? 56\n",
    " ! 57\n",
    " \" 58\n",
    " ' 59\n",
    " [ 60\n",
    " ] 61\n",
    " = 62\n",
    " : 63\n",
    " ( 64\n",
    " ) 65\n",
    " / 66\n",
    " 1 67\n",
    " 2 68\n",
    " 3 69\n",
    " 4 70\n",
    " 5 71\n",
    " 6 72\n",
    " 7 73\n",
    " 8 74\n",
    " 9 75\n",
    " 0 76\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <SPACE> 0\n",
      " a 1\n",
      " b 2\n",
      " c 3\n",
      " d 4\n",
      " e 5\n",
      " f 6\n",
      " g 7\n",
      " h 8\n",
      " i 9\n",
      " j 10\n",
      " k 11\n",
      " l 12\n",
      " m 13\n",
      " n 14\n",
      " o 15\n",
      " p 16\n",
      " q 17\n",
      " r 18\n",
      " s 19\n",
      " t 20\n",
      " u 21\n",
      " v 22\n",
      " w 23\n",
      " x 24\n",
      " y 25\n",
      " z 26\n",
      " A 27\n",
      " B 28\n",
      " C 29\n",
      " D 30\n",
      " E 31\n",
      " F 32\n",
      " G 33\n",
      " H 34\n",
      " I 35\n",
      " J 36\n",
      " K 37\n",
      " L 38\n",
      " M 39\n",
      " N 40\n",
      " O 41\n",
      " P 42\n",
      " Q 43\n",
      " R 44\n",
      " S 45\n",
      " T 46\n",
      " U 47\n",
      " V 48\n",
      " W 49\n",
      " X 50\n",
      " Y 51\n",
      " X 52\n",
      " - 53\n",
      " . 54\n",
      " , 55\n",
      " ? 56\n",
      " ! 57\n",
      " \" 58\n",
      " ' 59\n",
      " [ 60\n",
      " ] 61\n",
      " = 62\n",
      " : 63\n",
      " ( 64\n",
      " ) 65\n",
      " / 66\n",
      " 1 67\n",
      " 2 68\n",
      " 3 69\n",
      " 4 70\n",
      " 5 71\n",
      " 6 72\n",
      " 7 73\n",
      " 8 74\n",
      " 9 75\n",
      " 0 76\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(char_map_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<SPACE>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 52, 'Y': 51, '-': 53, '.': 54, ',': 55, '?': 56, '!': 57, '\"': 58, \"'\": 59, '[': 60, ']': 61, '=': 62, ':': 63, '(': 64, ')': 65, '/': 66, '1': 67, '2': 68, '3': 69, '4': 70, '5': 71, '6': 72, '7': 73, '8': 74, '9': 75, '0': 76}\n",
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'A', 28: 'B', 29: 'C', 30: 'D', 31: 'E', 32: 'F', 33: 'G', 34: 'H', 35: 'I', 36: 'J', 37: 'K', 38: 'L', 39: 'M', 40: 'N', 41: 'O', 42: 'P', 43: 'Q', 44: 'R', 45: 'S', 46: 'T', 47: 'U', 48: 'V', 49: 'W', 50: 'X', 51: 'Y', 52: 'X', 53: '-', 54: '.', 55: ',', 56: '?', 57: '!', 58: '\"', 59: \"'\", 60: '[', 61: ']', 62: '=', 63: ':', 64: '(', 65: ')', 66: '/', 67: '1', 68: '2', 69: '3', 70: '4', 71: '5', 72: '6', 73: '7', 74: '8', 75: '9', 76: '0'}\n"
     ]
    }
   ],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "#         char_map_str = char_map_str\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[0] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == 'é':\n",
    "                c = 'e'\n",
    "            elif c == \"“\" or c == \"”\":\n",
    "                c = '\"'\n",
    "            elif c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('', ' ')\n",
    "\n",
    "text_transform = TextTransform()\n",
    "print(text_transform.char_map)\n",
    "print(text_transform.index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnwAudioDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 audio_path=\"knnw_en.log_spectrogram.npy\",\n",
    "                 subtitle_lookup_path=\"knnw_en_sub.csv\",\n",
    "                 total_frames=1370582, \n",
    "                 total_duration=6396010):\n",
    "        \n",
    "        self.duration_per_frame = total_duration / total_frames\n",
    "        \n",
    "        self.audio = numpy.load(audio_path)\n",
    "        \n",
    "        self.subtitle_lookup = pandas.read_table(subtitle_lookup_path, \n",
    "                                                 sep = \";\", header=0)\n",
    "        \n",
    "        self.length = len(self.subtitle_lookup)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        start_time = self.subtitle_lookup.iloc[i, 1]\n",
    "        stop_time = self.subtitle_lookup.iloc[i, 2]\n",
    "        \n",
    "        audio_range = self.get_range(start_time, stop_time)\n",
    "        \n",
    "        audio_item = torch.as_tensor(self.audio[:,audio_range]).float().permute(1,0)\n",
    "        \n",
    "        subtitle_item = self.subtitle_lookup.iloc[i, 3]\n",
    "        subtitle_item = self.get_tokenization(subtitle_item)\n",
    "        label = torch.Tensor(text_transform.text_to_int(subtitle_item.lower())).int()\n",
    "        \n",
    "        return audio_item, label\n",
    "        \n",
    "    def get_index(self, time, start_flag):\n",
    "        \n",
    "        if start_flag == True:\n",
    "            return numpy.floor(time/self.duration_per_frame)\n",
    "        \n",
    "        else:\n",
    "            return numpy.ceil(time/self.duration_per_frame)\n",
    "        \n",
    "    def get_range(self, start_time, end_time):\n",
    "        \n",
    "        start_index = self.get_index(start_time, start_flag=True)\n",
    "        stop_index  = self.get_index(end_time, start_flag=False)\n",
    "        \n",
    "        return range(int(start_index), int(stop_index))\n",
    "    \n",
    "    def get_tokenization(self, subtitle_item):\n",
    "        \n",
    "        return subtitle_item\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        sorted_batch = batch\n",
    "        batch_x = [x for x,y in sorted_batch]\n",
    "        batch_y = [y for x,y in sorted_batch]\n",
    "        batch_x_pad = pad_sequence(batch_x, batch_first=True) #b,t,129\n",
    "        batch_y_pad = pad_sequence(batch_y, batch_first=True)\n",
    "        batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "        batch_y_lens = torch.LongTensor([len(x) for x in batch_y])\n",
    "        \n",
    "        return batch_x_pad, batch_y_pad, batch_x_lens, batch_y_lens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KnnwAudioDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103],\n",
       "         [-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103],\n",
       "         [-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103],\n",
       "         ...,\n",
       "         [-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103],\n",
       "         [-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103],\n",
       "         [-9.2103, -9.2103, -9.2103,  ..., -9.2103, -9.2103, -9.2103]]),\n",
       " tensor([20, 15,  8, 15,  0,  3, 15, 18, 16, 15, 18,  1, 20,  9, 15, 14],\n",
       "        dtype=torch.int32))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 15,  8, 15,  0,  3, 15, 18, 16, 15, 18,  1, 20,  9, 15, 14],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([1962, 129])\n"
     ]
    }
   ],
   "source": [
    "print((dataset.__getitem__(0)[1]))\n",
    "print(dataset.__getitem__(0)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further Reading: How do I split a custom dataset into training and test datasets?**\n",
    "\n",
    "https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 11785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler,collate_fn=KnnwAudioDataset.collate_fn,num_workers=8,pin_memory=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler,collate_fn=KnnwAudioDataset.collate_fn,num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers=2, input_size=129, out_size=27):\n",
    "        super(SpeechModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_size,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256))\n",
    "        self.lstm = nn.LSTM(256,hidden_size,num_layers,batch_first=True,bidirectional=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, 256),\n",
    "            nn.Linear(256, out_size))\n",
    "\n",
    "    def forward(self, x, length): #b,t,c\n",
    "        cnn_in = x.permute(0,2,1)\n",
    "        cnn_out = self.cnn(cnn_in)#b,c,t\n",
    "        x = cnn_out.permute(0,2,1)\n",
    "        lstm_in = pack_padded_sequence(x,length,batch_first=True,enforce_sorted=False)\n",
    "        output, hidden = self.lstm(lstm_in)\n",
    "        linear_in,linear_in_len = pad_packed_sequence(output,batch_first=True)\n",
    "        output = self.mlp(linear_in).log_softmax(2)\n",
    "        output = output.permute(1, 0, 2) #t,b,c\n",
    "        return output, linear_in_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    \n",
    "    for batch_num, (x, y, x_lens, y_lens) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y, x_lens, y_lens = x.to(device), y.to(device), x_lens.to(device), y_lens.to(device)\n",
    "        output, length = model(x, x_lens)\n",
    "        loss = criterion(output,y,length,y_lens)\n",
    "        training_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        del x\n",
    "        del y\n",
    "        del x_lens\n",
    "        del y_lens\n",
    "        \n",
    "    return training_loss/len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, data_loader, criterion, decoder):\n",
    "    model.eval()  \n",
    "    running_loss = 0.0\n",
    "    running_dist = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_num, (x, y, x_lens, y_lens) in enumerate(data_loader):\n",
    "        x, y, x_lens, y_lens = x.to(device), y.to(device), x_lens.to(device), y_lens.to(device)\n",
    "        output, length = model(x, x_lens)\n",
    "        loss = criterion(output,y,length,y_lens)\n",
    "        running_loss += loss.item()\n",
    "        total += x.shape[0]\n",
    "        \n",
    "        y_pred, _, _, y_pred_lens = decoder.decode(output.transpose(0,1), length)\n",
    "        for i in range(x.shape[0]):\n",
    "            pred_label = \"\".join(text_transform.index_map[j.item()] for j in y_pred[i, 0, :y_pred_lens[i, 0]])\n",
    "            true_label = \"\".join(text_transform.index_map[j.item()] for j in y[i, :y_lens[i]])\n",
    "            running_dist += lev.distance(pred_label, true_label)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        del x\n",
    "        del y\n",
    "        del x_lens\n",
    "        del y_lens\n",
    "            \n",
    "    running_loss /= len(data_loader)\n",
    "    running_dist /= total\n",
    "    return running_loss, running_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechModel(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv1d(129, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=77, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "beam_width = 1\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "lr = 2e-3\n",
    "weightDecay = 5e-5\n",
    "numEpochs = 40\n",
    "lowest_dist = 200\n",
    "model = SpeechModel(hidden_size, num_layers, 129, len(text_transform.index_map))\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weightDecay)\n",
    "criterion = nn.CTCLoss()\n",
    "decoder = CTCBeamDecoder(['$']*len(text_transform.index_map), beam_width=1, blank_id=0, log_probs_input=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience= 2, factor = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n",
      "train time:  14.064882278442383\n",
      "Epoch 1 , Train Loss: 4.973373317718506 Val Loss: 2.2110914058155484 , Val Dist: 34.19064748201439\n",
      "0.002\n",
      "train time:  13.8600914478302\n",
      "Epoch 2 , Train Loss: 2.1392555458205087 Val Loss: 2.084584421581692 , Val Dist: 34.19064748201439\n",
      "0.002\n",
      "train time:  14.056215763092041\n",
      "Epoch 3 , Train Loss: 2.1023689985275267 Val Loss: 2.0583986706203885 , Val Dist: 34.34892086330935\n",
      "0.002\n",
      "train time:  13.992499351501465\n",
      "Epoch 4 , Train Loss: 2.144597567830767 Val Loss: 2.0639430615637036 , Val Dist: 34.15107913669065\n",
      "0.002\n",
      "train time:  13.831193208694458\n",
      "Epoch 5 , Train Loss: 2.0773656095777238 Val Loss: 2.08118028110928 , Val Dist: 34.356115107913666\n",
      "0.002\n",
      "train time:  13.841840744018555\n",
      "Epoch 6 , Train Loss: 2.0534102303641184 Val Loss: 2.0999884605407715 , Val Dist: 33.74820143884892\n",
      "0.001\n",
      "train time:  13.98580527305603\n",
      "Epoch 7 , Train Loss: 2.037435095650809 Val Loss: 2.0310282111167908 , Val Dist: 34.197841726618705\n",
      "0.001\n",
      "train time:  14.075241088867188\n",
      "Epoch 8 , Train Loss: 2.026244124344417 Val Loss: 2.024415738052792 , Val Dist: 34.17625899280576\n",
      "0.001\n",
      "train time:  14.002511501312256\n",
      "Epoch 9 , Train Loss: 2.0260792817388262 Val Loss: 2.080734259552426 , Val Dist: 34.15107913669065\n",
      "0.001\n",
      "train time:  13.918895959854126\n",
      "Epoch 10 , Train Loss: 2.0487284660339355 Val Loss: 2.002908911969927 , Val Dist: 34.194244604316545\n",
      "0.001\n",
      "train time:  13.73206353187561\n",
      "Epoch 11 , Train Loss: 2.0275888425963267 Val Loss: 2.009455488787757 , Val Dist: 34.15107913669065\n",
      "0.001\n",
      "train time:  13.854070901870728\n",
      "Epoch 12 , Train Loss: 2.010150555201939 Val Loss: 2.013730241192712 , Val Dist: 34.14028776978417\n",
      "0.001\n",
      "train time:  14.025382280349731\n",
      "Epoch 13 , Train Loss: 2.0044908217021398 Val Loss: 2.008053673638238 , Val Dist: 33.95323741007194\n",
      "0.0005\n",
      "train time:  13.816991329193115\n",
      "Epoch 14 , Train Loss: 1.981085569517953 Val Loss: 1.9791559378306072 , Val Dist: 34.07194244604317\n",
      "0.0005\n",
      "train time:  14.106557607650757\n",
      "Epoch 15 , Train Loss: 1.9589930704661778 Val Loss: 1.956671290927463 , Val Dist: 34.29496402877698\n",
      "0.0005\n",
      "train time:  14.112458229064941\n",
      "Epoch 16 , Train Loss: 1.9550992608070374 Val Loss: 1.9450670679410298 , Val Dist: 34.16187050359712\n",
      "0.0005\n",
      "train time:  13.940342664718628\n",
      "Epoch 17 , Train Loss: 1.9458213652883256 Val Loss: 1.9371664391623602 , Val Dist: 33.66187050359712\n",
      "0.0005\n",
      "train time:  13.733293294906616\n",
      "Epoch 18 , Train Loss: 1.9472415804862977 Val Loss: 1.9459255735079448 , Val Dist: 34.12589928057554\n",
      "0.0005\n",
      "train time:  13.860147714614868\n",
      "Epoch 19 , Train Loss: 1.9419730578150067 Val Loss: 1.969495866033766 , Val Dist: 34.15827338129496\n",
      "0.0005\n",
      "train time:  14.060145378112793\n",
      "Epoch 20 , Train Loss: 1.94398706981114 Val Loss: 1.9271599650382996 , Val Dist: 34.118705035971225\n",
      "0.0005\n",
      "train time:  13.791433811187744\n",
      "Epoch 21 , Train Loss: 1.9199268562453133 Val Loss: 1.9347188671429951 , Val Dist: 33.6294964028777\n",
      "0.0005\n",
      "train time:  13.789184331893921\n",
      "Epoch 22 , Train Loss: 1.9241983805383955 Val Loss: 1.9137500392066107 , Val Dist: 34.06115107913669\n",
      "0.0005\n",
      "train time:  14.110300540924072\n",
      "Epoch 23 , Train Loss: 1.909804586001805 Val Loss: 1.928177211019728 , Val Dist: 34.14028776978417\n",
      "0.0005\n",
      "train time:  13.95969271659851\n",
      "Epoch 24 , Train Loss: 1.9118097628865922 Val Loss: 1.9188577797677782 , Val Dist: 33.56115107913669\n",
      "0.0005\n",
      "train time:  13.792051315307617\n",
      "Epoch 25 , Train Loss: 1.9095615557261876 Val Loss: 1.9081447455618117 , Val Dist: 34.02517985611511\n",
      "0.0005\n",
      "train time:  13.676661014556885\n",
      "Epoch 26 , Train Loss: 1.9061169402939933 Val Loss: 1.9059071011013455 , Val Dist: 33.84892086330935\n",
      "0.0005\n",
      "train time:  13.664735078811646\n",
      "Epoch 27 , Train Loss: 1.9113830907004221 Val Loss: 1.9204297529326544 , Val Dist: 33.5431654676259\n",
      "0.0005\n",
      "train time:  13.702507734298706\n",
      "Epoch 28 , Train Loss: 1.8965965049607414 Val Loss: 1.9027902881304424 , Val Dist: 33.68705035971223\n",
      "0.0005\n",
      "train time:  13.785871505737305\n",
      "Epoch 29 , Train Loss: 1.8942790729658945 Val Loss: 1.8933781054284837 , Val Dist: 33.95323741007194\n",
      "0.0005\n",
      "train time:  13.909623146057129\n",
      "Epoch 30 , Train Loss: 1.8856825709342957 Val Loss: 1.9255248705546062 , Val Dist: 33.52517985611511\n",
      "0.0005\n",
      "train time:  14.079620838165283\n",
      "Epoch 31 , Train Loss: 1.8919348342078073 Val Loss: 1.9134062594837613 , Val Dist: 33.81294964028777\n",
      "0.0005\n",
      "train time:  13.973411560058594\n",
      "Epoch 32 , Train Loss: 1.8820549658366612 Val Loss: 1.9056328733762105 , Val Dist: 33.827338129496404\n",
      "0.00025\n",
      "train time:  13.909146547317505\n",
      "Epoch 33 , Train Loss: 1.8641319462231227 Val Loss: 1.931856718328264 , Val Dist: 33.54676258992806\n",
      "0.00025\n",
      "train time:  13.798503637313843\n",
      "Epoch 34 , Train Loss: 1.8472148929323469 Val Loss: 1.9068454967604742 , Val Dist: 34.00359712230216\n",
      "0.00025\n",
      "train time:  13.870954513549805\n",
      "Epoch 35 , Train Loss: 1.8451301745006017 Val Loss: 1.8994399971432157 , Val Dist: 33.68345323741007\n",
      "0.000125\n",
      "train time:  13.986172914505005\n",
      "Epoch 36 , Train Loss: 1.8311008896146501 Val Loss: 1.8933535019556682 , Val Dist: 33.84892086330935\n",
      "0.000125\n",
      "train time:  13.822870016098022\n",
      "Epoch 37 , Train Loss: 1.8278060810906547 Val Loss: 1.8962467246585422 , Val Dist: 33.84532374100719\n",
      "0.000125\n",
      "train time:  14.062954425811768\n",
      "Epoch 38 , Train Loss: 1.8278963310377938 Val Loss: 1.8796094722217984 , Val Dist: 33.96762589928058\n",
      "0.000125\n",
      "train time:  14.255927085876465\n",
      "Epoch 39 , Train Loss: 1.8241049987929208 Val Loss: 1.8651179207695856 , Val Dist: 33.81294964028777\n",
      "0.000125\n",
      "train time:  13.720424175262451\n",
      "Epoch 40 , Train Loss: 1.8189502682004657 Val Loss: 1.8660352097617254 , Val Dist: 33.856115107913666\n"
     ]
    }
   ],
   "source": [
    "for i in range(numEpochs):\n",
    "    print(get_lr(optimizer))\n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    end = time.time()\n",
    "    print(\"train time: \", end-start)\n",
    "    val_loss, val_dist = evaluation(model, validation_loader, criterion, decoder)\n",
    "    if(val_dist<lowest_dist): \n",
    "            torch.save({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_dist': val_dist\n",
    "            }, 'model_1')\n",
    "            lowest_dist = val_dist\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"Epoch\", i+1, \", Train Loss:\", train_loss, \"Val Loss:\", val_loss, \", Val Dist:\", val_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.52517985611511\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "model = SpeechModel(hidden_size, num_layers, 129, len(text_transform.index_map))\n",
    "checkpoint = torch.load(\"model_1\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "e = checkpoint['epoch']\n",
    "lowest_dist = checkpoint['val_dist']\n",
    "print(lowest_dist)\n",
    "print(e)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
